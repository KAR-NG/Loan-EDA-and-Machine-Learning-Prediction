---
title: "loan"
author: "Kar Ng"
date: "1/24/2022"
output: 
  github_document: 
    toc: true
    toc_depth: 4
always_allow_html: yes
---

***


***


## 1 SUMMARY




## 2 R PACKAGES

```{r}
library(tidyverse)
library(skimr)
library(caret)
library(kableExtra)
library(glmnet)
library(MASS)

```

## 3 INTRODUCTION

It is a machine learning project to demonstrate my technical experiences. This project uses datasets that are related to loan borrowing. 

I will use statistical modeling in machine learning to study the datasets and to extract important variables that are related to loan approval by the loan provider. I will also create predictive models that are able to make accurate prediction when new data are coming.

Information to be analysed include gender, marital status, number of dependents, education level, self employment, applicant income, co-applicant income, loan amount, loan amount term, credit history, and area of respondents' property. 

Two datasets are given, one is named 'train.data' and the another named 'test.data'. Both datasets have same information but the train.data has one more variable 'loan status', which contains the loan results.

There will be 3 datasets involved in this project. During modeling, I will split the train.data into two sbuject, one is a smaller subset with a name **"train_set"** and another named **"test_set"**. The **train_set** will be used to make various models and the **test_set** will be used to evaluate these models.

Ultimately, the best model will be used to predict the 'test.data'. 



## 4 DATA PREPARATION

Data is downloaded from the [Kaggle](https://www.kaggle.com/altruistdelhite04/loan-prediction-problem-dataset). Two datasets are downloaded, a train and a test data.

### 4.1 Data import

The train and the test data are imported in following code chunk.

```{r}
train.data <- read.csv("train_loan.csv", na.strings = c("", "NA"))
test.data <- read.csv("test_loan.csv", na.strings = c("", "NA"))

```

### 4.2 Data exploration

There are 13 variables for the train.data and 12 variables for the test.data. Both dataset have similar variable, however there is an additional variable in train.data, the "Loan_Status" which records the loan outcome. Test.data is the dataset that requiring me to make prediction using the train.data. 

Following show the first 6 rows of the train.data and the test.data.

```{r}
head(train.data)

```

```{r}
head(test.data)
     
```
From structural analysis, 

* There are 614 observations (rows) in the train.data dataset and 367 observations in the test.data dataset.      
* Train.data has the last variable 'Loan_status' that has either 'Y' or 'N' to indicate the success of a loan.  
* The 'Loan_Amount_Term', which is the length of time a loan is to be completely paid off, has repeated levels. For example, the replication of 360. It may indicate that this variable has categorical nature and should be converted in factor type. 

```{r}
str(train.data)

```

```{r}
str(test.data)

```

To detect missing values (NA), 

* In the train.data,  
  * There are 8 character and 5 numerical variables.
  * The dataset is quite complete (checking on the **n_missing** and **complete_rate**).   
  * There are many variables with a few missing values, and they have complete_rate higher 90%.  
  * The variable **Credit_History** is either 1 or 0, which is a binary variable and should be converted into factor during data cleaning. 
  
```{r}
skim_without_charts(train.data)

```
* The same situation goes to the test.data dataset. 

```{r}
skim_without_charts(test.data)

```
## 5 DATA CLEANING AND MANIPULATION

### 5.1 Train.data 

#### 5.1.1 Remove ID and factor conversion

First, I will remove the "Loan_ID" and convert all character variables into factor because they are categorical variable. I remove LOan_ID because it is meaningless for predictive analysis. 

Converting variables into factors will help my analysis because it gives the data a grouping features which will enable useful R function as well as visualisation in later stage. 

```{r}

train.data <- train.data %>% 
  dplyr::select(-Loan_ID) %>%                                    # Remove Loan_ID 
  mutate_if(is_character, as.factor) %>%                  # Convert all character into factor.
  mutate(Credit_History = as.factor(Credit_History),      # Convert Credit_History into factor.
         Loan_Amount_Term = as.factor(Loan_Amount_Term))  # Convert Loan_Amount_Term into factor.

```

After converting categorical variables into factor, following function help to summarise the dataset.  

```{r}

summary(train.data)

```
Many variables have missing values, as denoted by "NA's". Missing values will be filled up in next section.


#### 5.1.2 Replacing NA

Following codes replace all the NA with respective mode, which is the most occurring category of variable they belong. It is a decision after carefully examining its feasibility, these missing values are less than 5%, and their respective most occurring category have frequencies that are way higher than the rest of the categories. 

```{r}
train.data <- train.data %>% 
  mutate(Gender = replace_na(Gender, "Male"),
         Married = replace_na(Married, "Yes"),
         Dependents = replace_na(Dependents, '0'),
         Self_Employed = replace_na(Self_Employed, 'No'),
         Loan_Amount_Term = replace_na(Loan_Amount_Term, '360'))
  
summary(train.data)

```

**Credit History**

Regarding the NA in credit history, I found that the 50 NA is too many (8%), and is quite close to 89 of "0". I decided to make it a new level. 

```{r}
50/(89+475+50) 

```
```{r}
train.data <- train.data %>% 
  mutate(Credit_History = as.character(Credit_History),
         Credit_History = replace_na(Credit_History, "Not_sure"),
         Credit_History = as.factor(Credit_History))
```


**LoanAmount**

There are 22 missing values out from 614 rows of data, which is only 3.5%. I will remove these missing values. According to Schafer (1999), the paper asserted that a missing rate of 5% or less is inconsequential.

```{r}
22/614 * 100
```
```{r}
train.data <- train.data %>% na.omit()

```

### 5.2 Test data 

#### 5.1.1 Remove ID and factor conversion

Same process applies to test data. 

```{r}

test.data <- test.data %>% 
  dplyr::select(-Loan_ID) %>%                                    # Remove Loan_ID 
  mutate_if(is_character, as.factor) %>%                  # Convert all character into factor.
  mutate(Credit_History = as.factor(Credit_History),      # Convert Credit_History into factor.
         Loan_Amount_Term = as.factor(Loan_Amount_Term))  # Convert Loan_Amount_Term into factor.

summary(test.data)

```
#### 5.1.2 Replacing NA

```{r}
test.data <- test.data %>% 
  mutate(Gender = replace_na(Gender, "Male"),
         Dependents = replace_na(Dependents, '0'),
         Self_Employed = replace_na(Self_Employed, 'No'),
         Loan_Amount_Term = replace_na(Loan_Amount_Term, '360'))
  
summary(test.data)

```

**Credit History**

For credit history, I will transfer 29 of "NA" to "1", because it is very likely that all these 29 NA are actually 1  because 1 is the most occuring category of that variable.  

```{r}
test.data <- test.data %>% 
  mutate(Credit_History = as.character(Credit_History),
         Credit_History = replace_na(Credit_History, "1"),
         Credit_History = as.factor(Credit_History))

summary(test.data)

```

**Loan Amount**

There are only 5 NA in the variable, I will remove these missing values. 

```{r}
test.data <- test.data %>% 
  na.omit()

```

Both datasets have now been cleaned and are ready for analysis. 


### 5.3 Feature Engineering

**On Train.data**

This section creates 3 new variables based on original variables. 

1. total_income (Applicant Income + Co-applicant income)

This is synthesised by adding "ApplicantIncome" and "CoapplicantIncome" to find the total income of an applicant. 

```{r}
train.data <- train.data %>% 
  mutate(total_income = ApplicantIncome + CoapplicantIncome) %>% 
  relocate(total_income, .after = CoapplicantIncome)

```

2. Loan_Amt_per_term (Loan/month)

This is synthesised by dividing "LoanAmount" with "Loan_Amount_Term" to, interestingly, find out would the loan amount with the unit of per month affect the approval of a loan application. 

```{r}
train.data <- train.data %>% 
  mutate(Loan_Amt_per_term = round(LoanAmount/as.numeric(Loan_Amount_Term), 2)) %>% 
  relocate(Loan_Amt_per_term, .after = Loan_Amount_Term)

```


3. Income provider (one incomer or two)

This variable is created based on how many incomers in an application. Two levels have been detected for this new variable:

* "Applicant": Only the primary applicant has income

* "Both": Both the primary applicant and co-applicant have incomes

```{r}
train.data <- train.data %>% 
  mutate(Income_provider = case_when(CoapplicantIncome == 0 ~ "Applicant",
                                     ApplicantIncome == 0 ~ "Co-applicant",
                                     TRUE ~ "Both"),
         Income_provider = as.factor(Income_provider)) %>% 
  relocate(Income_provider, .after = total_income)

```

**On Test.data**

The same operation applies to test.data.


1. total_income

```{r}
test.data <- test.data %>% 
  mutate(total_income = ApplicantIncome + CoapplicantIncome) %>% 
  relocate(total_income, .after = CoapplicantIncome)

```

2. Loan_Amt_per_term

```{r}
test.data <- test.data %>% 
  mutate(Loan_Amt_per_term = round(LoanAmount/as.numeric(Loan_Amount_Term), 2)) %>% 
  relocate(Loan_Amt_per_term, .after = Loan_Amount_Term)

```


3. Income provider (one incomer or two)

```{r}
test.data <- test.data %>% 
  mutate(Income_provider = case_when(CoapplicantIncome == 0 ~ "Applicant",
                                     ApplicantIncome == 0 ~ "Co-applicant",
                                     TRUE ~ "Both"),
         Income_provider = as.factor(Income_provider)) %>% 
  relocate(Income_provider, .after = total_income)

```


## 6 Exploratory Data Analysis (EDA)

In this section, I will use the **train.data** dataset to analyse general trends in the dataset because **train.data** has "Loan_Status" which is the responding variable. The relationship between Loan_Status with various variables in the dataset will be studied.

```{r}
names(train.data)

```
This exploratory data analysis will serve as a tool to understand the general trends underneath the data before getting into machine learning and statistical modeling.

### 6.1 Overall Approval Rate 

Most of the applications were approved from the train dataset were approved. 411 applications (70%) were approved, denoted with the symbol "Y"， whereas 181 of applications (30%) were rejected, denoted by "N".

The loan status is the responding variable of this analysis and therefore the unbalanced sample size from both "Y" and "N" may badly affect the predictive model (sensitivity and specificity) built in the later machine learning section. It is a good note here and will be considered during models building and evaluation.

```{r, message=FALSE, warning=FALSE}

# set up dataframe

df6.1.1 <- train.data %>% 
  dplyr::select(Loan_Status) %>% 
  group_by(Loan_Status) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  mutate(total = sum(count),
         per = round(count/total, 1))

# plot

ggplot(df6.1.1, aes(x = "", y = count, fill = Loan_Status)) +
  geom_bar(stat = 'identity', colour = "black") +
  coord_polar(theta = "y", start = 0) +
  theme_minimal() +
  theme(axis.title = element_blank(),
        legend.position = "none",
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_label(aes(label = paste0(Loan_Status, "\n", count, " (", per*100, " %)")),
             position = position_stack(vjust = 0.5),
             size = 4) +
  labs(title = "70% Of Applications have been Approved",
       subtitle = "(Train data)")  

```

### 6.2 Would Gender affect Loan Approval

It will be interesting to see the number of female and male applicants and would gender affect loan approval. Data shows that:

* There were lesser female applicants (109) than male applicants (483).

* However, the loan success rate of both gender are the same, both arrived at 70%. There is no detection of gender bias from the dataset. 

```{r, fig.width = 8, message=FALSE}

# set up dataframe

df6.1.2 <- train.data %>% 
  dplyr::select(Loan_Status, Gender) %>% 
  group_by(Loan_Status, Gender) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  group_by(Gender) %>% 
  mutate(total = sum(count),
         per = round(count/total, 1))

# plot

ggplot(df6.1.2, aes(x = "", y = count, fill = Loan_Status)) +
  geom_bar(stat = 'identity'， colour = "black") +
  coord_polar(theta = "y", start = 0) +
  theme_minimal() +
  theme(axis.title = element_blank(),
        legend.position = "none",
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_label(aes(label = paste0(Loan_Status, "\n", count, " (", per*100, " %)")),
             position = position_stack(vjust = 0.5),
             size = 3) +
  labs(title = "Both Gender have similar proportion",
       subtitle = "(Train data)") +
  facet_wrap(~ Gender)


```
Female Applicants:

```{r}
73+36
```
Male Applicants:

```{r}
145+338

```

### 6.3 Income and Loan Approval

There are three type of income categories to be analysed, which are:

* "ApplicantIncome" - the income of the primary applicant  
* "CoapplicantIncome" - the income of co-applicant  
* "total_income" - the total income of both primary applicant and co-applicant  

```{r, fig.width=8, fig.height=7}

# set up dataframe

df6.2 <- train.data %>% 
  dplyr::select(ApplicantIncome, CoapplicantIncome, total_income, Loan_Status) %>% 
  pivot_longer(c(1:3), names_to = "cat", values_to = "income") 

# plot

p1 <- ggplot(df6.2, aes(x = Loan_Status, y = income, shape = Loan_Status, colour = Loan_Status)) +
  geom_jitter(alpha = 0.5) + 
  geom_boxplot(alpha = 0,
               outlier.shape = NA,
               color = "black") +
  facet_wrap(~cat) +
  theme_bw() +
  theme(strip.text = element_text(size = 14),
        plot.title = element_text(face = "bold"),
        legend.position = "none") +
  labs(x = "Loan Status",
       title = "Income Category vs Loan Status")

p2 <- ggplot(df6.2, aes(x = Loan_Status, y = log(income), shape = Loan_Status, colour = Loan_Status)) +
  geom_jitter(alpha = 0.5) + 
  geom_boxplot(alpha = 0,
               outlier.shape = NA,
               color = "black") +
  facet_wrap(~cat) +
  theme_bw() +
  theme(strip.text = element_text(size = 14),
        plot.title = element_text(face = "bold"),
        legend.position = "none")+
  labs(x = "Loan Status",
       title = "Logged Income Category vs Loan Status")

library(ggpubr)

ggarrange(p1, p2, 
          nrow = 2, 
          ncol = 1,
          labels =c("A", "B"))

```

I hypothesise that whoever have higher income, will have application approved, therefore, the boxplot of "Y" should be at a higher position than "N". 

Interestingly, results show that regardless of whether the income is based on original scale or log transformed, 

* all three income data has no obvious impact on loan approval.   
* Boxplots of 3 type of incomes "ApplicantIncome", "CoapplicantIncome" and "total_income" overlap with each other near perfectly. "Note: total_income is the combination of income from applicant and co-applicant."  

It indicates that the criteria of loan approval is not merely based on income. 


### 6.4 Number of incomers


```{r}
train.set

```




### 6.5 Marrital Status, Depedents and Education 

This section studies the effect of marital status, numbers of dependents, and education levels of an applicant on his/her loan status in the train.data dataset.

Results show that:

* There is no obvious trend for the number of dependents on loan approval.   
* 8% more applicants with graduate education level had their loan application approved.   
* 9% more applicants with a married status had their loan approved.   


```{r, fig.width=9, fig.height=7}
# set up df

df6.4 <- train.data %>% 
  dplyr::select(Married, Dependents, Education, Loan_Status) %>% 
  pivot_longer(c(1:3), names_to = "variables", values_to = "values") %>% 
  group_by(Loan_Status, variables, values) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  group_by(variables, values) %>% 
  mutate(total = sum(count),
         per = paste0(round(count/total,2)*100, "%"),
         lab = paste0(values, "\n", "n = (", total, ")"))

# plot

ggplot(df6.4, aes(x = lab, y = count, fill = Loan_Status)) +
  geom_histogram(stat = "identity", position = "fill") +
  facet_wrap(~variables, scale = "free") +  
  theme_bw() +
  theme(strip.text = element_text(size = 14),
        plot.title = element_text(face = "bold"),
        legend.position = "top",
        axis.title.x = element_text(margin = margin(8, 0, 0, 0)))+
  labs(x = "Loan Status",
       y = " ",
       title = "Dependents, Education, and Marrital Status on Loan Status") +
  geom_label(aes(label = per), 
             position = "fill", 
             vjust = 2) 

```


### 6.6 Credit_History, Property_Area, Self_Employed

Insights show that:

* If an applicant does not have credit history, 90% of the chance that his/her application would be rejected. Credit history will help tremendous in getting loan application approved.

* There are 3 different types of property area, semiurban has the highest approval rate (77%), followed by urban at 68%, and lastly semi-urban at 62%. 

* Self-employment would not affect the success rate of loan approval.

```{r, fig.width=9, fig.height=7}
# Set up dataframe

df6.5 <- train.data %>% 
  dplyr::select(Self_Employed, Credit_History, Property_Area, Loan_Status) %>% 
  pivot_longer(c(1:3), names_to = "variables", values_to = "values") %>% 
  group_by(Loan_Status, variables, values) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  group_by(variables, values) %>% 
  mutate(total = sum(count),
         per = paste0(round(count/total,2)*100, "%"),
         lab = paste0(values, "\n", "n = (", total, ")"))

# plot

ggplot(df6.5, aes(x = lab, y = count, fill = Loan_Status)) +
  geom_histogram(stat = "identity", position = "fill") +
  facet_wrap(~variables, scale = "free") +  
  theme_bw() +
  theme(strip.text = element_text(size = 14),
        plot.title = element_text(face = "bold"),
        legend.position = "top",
        axis.title.x = element_text(margin = margin(8, 0, 0, 0)))+
  labs(x = "Loan Status",
       y = " ",
       title = "Self-Employed, Credit History, and Property Area on Loan Status") +
  geom_label(aes(label = per), 
             position = "fill", 
             vjust = 1.5) 

```


### 6.7 EDA summary

From the exploratory data analysis, there are some visual trends in education status, marital status and property area that they may impact the approval of a loan application. The most obvious limiting factor is whether the applicant has previous credit history. 

Apart from the above visualisation analysis, Statistical modeling (machine learning) will be carried out to help extract the inner trends in the data and ultimately build an effective model to predict the imported test.data dataset.


## 7 Machine Learning

### 7.1 Data partitioning

There are two datasets imported, the **train.data** and the **test.data**. However, only the **train.data** datasets have the responding variable, **Loan_Status**. Therefore, my strategies will be:

* Split the train.data dataset into proportioned **train.set** and **test.set**. This test.set will be used to assessing models built from the **train.set**.

* Lastly, the best model will be used to predict the **test.data**.

There are several ratio options for data partitioning, such as 50:50, 60:40, or 80:20 split of the data into train and test set. Most popular ranges are 40:60, 30:70, and 20:80, and usually one can pick the 30:70 as it is in the "median" position. 

However, data partitioning is largely depends on how much data we have. We should try our best to ensure there is enough data to train an effective model as well as enough data for the test set to assess the performance of the model. 

I am going for 70:30 split of the train.data into train and test set to ensure there is sufficient enough for the test set for model evaluation purpose. 

```{r}
set.seed(123)

# Data partitioning

ind <- train.data$Loan_Status %>% createDataPartition(list = F, p = 0.7)

# train test split

train.set <- train.data[ind, ]
test.set <- train.data[-ind, ]

```

The train.data is a small dataset consisting only 592 rows of observation, and data partition splits it into 70% of train.set with 415 rows of observation (~70%) and 177 rows of observation (~30%).

Data size of **train.set**: 

```{r}
dim(train.set)[1]

```
Data size of **test.set**: 

```{r}
dim(test.set)[1]

```
The test set has 54 and 123 of "N" and "Y". There would be a little concern for "N" as its data size is not very large and therefore specificity of the model built would be affected, however, it will only be confirmed after building and test the model. 

```{r}

table(test.set$Loan_Status)

```

### 7.2 About Modeling 

It should be aware that no model is 100% accurate in machine learning. Therefore, different models are generally built based on different algorithms to search for the model that can do the best job in prediction. 



### 7.3 Logistic Regression

This project faces a binary / binomial problem which means the responding variable has only 2 values, which is either yes or no. Logistic regression will be applied. Logistic regression can also be used for multinomial situation where responding variable has more than 2 levels. 

For logistic regression, it is not required to test the linear relationship between predictors and the responding variable, and therefore the normality of error terms.

Following show the results of a binomial logistic regression model with a 10-fold cross validation (cv )and a cv repetation of 3 times. 

```{r, warning=FALSE}
model_lo <- train(Loan_Status ~ ., 
                        data = train.set,
                        method = "glm",
                        family = "binomial",
                        trControl = trainControl(method = "repeatedcv",
                                                 number = 10,
                                                 repeats = 3))

summary(model_lo)

```

*Insights*

* Results show that variable **total_income** and the level "480" in the variable **Loan_Amount_per_term** are redundant because all other variable have provided sufficient information at 100% level in explaining the variability in the responding variables. 

* The model shows that most variables are not significantly related to the loan status (which is the responding variable), except for credit history and property area. 

* When there is credit history of "1" or "not sure", the log odds of loan approval go up in a positive significant way. 

* Semi-urban property area contribute to the log odd of loan approval positively.

Therefore, a new model is build with only credit history and property area. The result is shown below. 

```{r}
model_lo2 <- train(Loan_Status ~ Credit_History + Property_Area, 
                        data = train.set,
                        method = "glm",
                        family = "binomial",
                        trControl = trainControl(method = "repeatedcv",
                                                 number = 10,
                                                 repeats = 3))

summary(model_lo2)
  
```
"Urban" of property area cannot be removed because it is part of levels of the "Property_Area". 

**Prediction on Train Set to detect overfitting**

This result is used to compare with prediction results on test set, there would be overfitting if there is a large difference in performance between the both sets. 

```{r}
pred <- model_lo2 %>% predict(train.set, type = 'raw')  
confusionMatrix(pred, train.set$Loan_Status, positive = "Y") 
```

*Insights*

* The accuracy rate is very high at 81.2%.  
* The model has extremely good sensitivity (actual positive) at 98.6%.  
* The model has very low specificity (actual positive) at 41.7%.  
* "No Information Rate" is 69% which is lower than the accuracy rate as well as outside of the range of 95% CI, it indicates that it is a useful model to use. 

**Prediction with test data**

```{r}

pred <- model_lo2 %>% predict(test.set, type = 'raw') 

confusionMatrix(pred, test.set$Loan_Status, positive = "Y")

```
*Insights*

* Prediction on test set has accuracy of 81.9%, which is very close to the result of train set at 81.2%.  
* Sensitivity (actual positive) is 97.6%, which is very close to the result of train set at 98.6%.  
* Specificity (actual negative) is 46.3%, which is not too far away from the train set at 41.7%.   
* "No Information Rate" is 69% which is lower than the accuracy rate as well as outside of the range of 95% CI, it indicates that it is a useful model to use.  

Base on the performance of the both models based on the train and the test sets, I say that there is no overfitting and the model is good to be used. However, specificity is 




##  REFERENCE

https://www.kaggle.com/altruistdelhite04/loan-prediction-problem-dataset
