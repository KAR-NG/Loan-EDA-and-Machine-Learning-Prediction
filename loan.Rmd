---
title: "loan"
author: "Kar Ng"
date: "1/24/2022"
output: 
  github_document: 
    toc: true
    toc_depth: 4
always_allow_html: yes
---

***


***


## 1 SUMMARY




## 2 R PACKAGES

```{r}
library(tidyverse)
library(skimr)
library(caret)
library(kableExtra)

```

## 3 INTRODUCTION

It is a machine learning project to demonstrate my technical experiences. This project uses datasets that are related to loan borrowing. 

I will use statistical modeling in machine learning to study the datasets and to extract important variables that are related to loan approval by the loan provider. I will also create predictive models that are able to make accurate prediction when new data are coming.

Information to be analysed include gender, marital status, number of dependents, education level, self employment, applicant income, co-applicant income, loan amount, loan amount term, credit history, and area of respondents' property. 

Two datasets are given, one is named 'train.data' and the another named 'test.data'. Both datasets have same information but the train.data has one more variable 'loan status', which contains the loan results.

There will be 3 datasets involved in this project. During modeling, I will split the train.data into two sbuject, one is a smaller subset with a name **"train_set"** and another named **"test_set"**. The **train_set** will be used to make various models and the **test_set** will be used to evaluate these models.

Ultimately, the best model will be used to predict the 'test.data'. 



## 4 DATA PREPARATION

Data is downloaded from the [Kaggle](https://www.kaggle.com/altruistdelhite04/loan-prediction-problem-dataset). Two datasets are downloaded, a train and a test data.

### 4.1 Data import

The train and the test data are imported in following code chunk.

```{r}
train.data <- read.csv("train_loan.csv", na.strings = c("", "NA"))
test.data <- read.csv("test_loan.csv", na.strings = c("", "NA"))

```

### 4.2 Data exploration

There are 13 variables for the train.data and 12 variables for the test.data. Both dataset have similar variable, however there is an additional variable in train.data, the "Loan_Status" which records the loan outcome. Test.data is the dataset that requiring me to make prediction using the train.data. 

Following show the first 6 rows of the train.data and the test.data.

```{r}
head(train.data)

```

```{r}
head(test.data)
     
```
From structural analysis, 

* There are 614 observations (rows) in the train.data dataset and 367 observations in the test.data dataset.      
* Train.data has the last variable 'Loan_status' that has either 'Y' or 'N' to indicate the success of a loan.  
* The 'Loan_Amount_Term', which is the length of time a loan is to be completely paid off, has repeated levels. For example, the replication of 360. It may indicate that this variable has categorical nature and should be converted in factor type. 

```{r}
str(train.data)

```

```{r}
str(test.data)

```

To detect missing values (NA), 

* In the train.data,  
  * There are 8 character and 5 numerical variables.
  * The dataset is quite complete (checking on the **n_missing** and **complete_rate**).   
  * There are many variables with a few missing values, and they have complete_rate higher 90%.  
  * The variable **Credit_History** is either 1 or 0, which is a binary variable and should be converted into factor during data cleaning. 
  
```{r}
skim_without_charts(train.data)

```
* The same situation goes to the test.data dataset. 

```{r}
skim_without_charts(test.data)

```
## 5 DATA CLEANING AND MANIPULATION

### 5.1 Train.data 

#### 5.1.1 Remove ID and factor conversion

First, I will remove the "Loan_ID" and convert all character variables into factor because they are categorical variable. I remove LOan_ID because it is meaningless for predictive analysis. 

Converting variables into factors will help my analysis because it gives the data a grouping features which will enable useful R function as well as visualisation in later stage. 

```{r}

train.data <- train.data %>% 
  select(-Loan_ID) %>%                                    # Remove Loan_ID 
  mutate_if(is_character, as.factor) %>%                  # Convert all character into factor.
  mutate(Credit_History = as.factor(Credit_History),      # Convert Credit_History into factor.
         Loan_Amount_Term = as.factor(Loan_Amount_Term))  # Convert Loan_Amount_Term into factor.

```

After converting categorical variables into factor, following function help to summarise the dataset.  

```{r}

summary(train.data)

```
Many variables have missing values, as denoted by "NA's". Missing values will be filled up in next section.


#### 5.1.2 Replacing NA

Following codes replace all the NA with respective mode, which is the most occurring category of variable they belong. It is a decision after carefully examining its feasibility, these missing values are less than 5%, and their respective most occurring category have frequencies that are way higher than the rest of the categories. 

```{r}
train.data <- train.data %>% 
  mutate(Gender = replace_na(Gender, "Male"),
         Married = replace_na(Married, "Yes"),
         Dependents = replace_na(Dependents, '0'),
         Self_Employed = replace_na(Self_Employed, 'No'),
         Loan_Amount_Term = replace_na(Loan_Amount_Term, '360'))
  
summary(train.data)

```

**Credit History**

Regarding the NA in credit history, I found that the 50 NA is too many (8%), and is quite close to 89 of "0". I decided to make it a new level. 

```{r}
50/(89+475+50) 

```
```{r}
train.data <- train.data %>% 
  mutate(Credit_History = as.character(Credit_History),
         Credit_History = replace_na(Credit_History, "Not_sure"),
         Credit_History = as.factor(Credit_History))
```


**LoanAmount**

There are 22 missing values out from 614 rows of data, which is only 3.5%. I will remove these missing values. According to Schafer (1999), the paper asserted that a missing rate of 5% or less is inconsequential.

```{r}
22/614 * 100
```
```{r}
train.data <- train.data %>% na.omit()

```

### 5.2 Test data 

#### 5.1.1 Remove ID and factor conversion

Same process applies to test data. 

```{r}

test.data <- test.data %>% 
  select(-Loan_ID) %>%                                    # Remove Loan_ID 
  mutate_if(is_character, as.factor) %>%                  # Convert all character into factor.
  mutate(Credit_History = as.factor(Credit_History),      # Convert Credit_History into factor.
         Loan_Amount_Term = as.factor(Loan_Amount_Term))  # Convert Loan_Amount_Term into factor.

summary(test.data)

```
#### 5.1.2 Replacing NA

```{r}
test.data <- test.data %>% 
  mutate(Gender = replace_na(Gender, "Male"),
         Dependents = replace_na(Dependents, '0'),
         Self_Employed = replace_na(Self_Employed, 'No'),
         Loan_Amount_Term = replace_na(Loan_Amount_Term, '360'))
  
summary(test.data)

```

**Credit History**

For credit history, I will transfer 29 of "NA" to "1", because it is very likely that all these 29 NA are actually 1  because 1 is the most occuring category of that variable.  

```{r}
test.data <- test.data %>% 
  mutate(Credit_History = as.character(Credit_History),
         Credit_History = replace_na(Credit_History, "1"),
         Credit_History = as.factor(Credit_History))

summary(test.data)

```

**Loan Amount**

There are only 5 NA in the variable, I will remove these missing values. 

```{r}
test.data <- test.data %>% 
  na.omit()

```

Both datasets have now been cleaned and are ready for analysis. 


### 5.3 Feature Engineering

This section creates new variables based on original variables. 

1. total_income

This is synthesised by adding "ApplicantIncome" and "CoapplicantIncome" to find the total income of an applicant. 

```{r}
train.data <- train.data %>% 
  mutate(total_income = ApplicantIncome + CoapplicantIncome) %>% 
  relocate(total_income, .after = CoapplicantIncome)

```

2. Loan_Amt_per_term

This is synthesised by dividing "LoanAmount" with "Loan_Amount_Term" to, interestingly, find out would the loan amount with the unit of per month affect the approval of a loan application. 

```{r}
train.data <- train.data %>% 
  mutate(Loan_Amt_per_term = round(LoanAmount/as.numeric(Loan_Amount_Term), 2)) %>% 
  relocate(Loan_Amt_per_term, .after = Loan_Amount_Term)

```


## 6 Exploratory Data Analysis (EDA)

In this section, I will use the **train.data** dataset to analyse general trends in the dataset because **train.data** has "Loan_Status" which is the responding variable. The relationship between Loan_Status with various variables in the dataset will be studied.

```{r}
names(train.data)

```
This exploratory data analysis will serve as a tool to understand the general trends underneath the data before getting into machine learning and statistical modeling.

### 6.1 Overall Approval Rate 

Most of the applications were approved from the train dataset were approved. 411 applications (70%) were approved, denoted with the symbol "Y"ï¼Œ whereas 181 of applications (30%) were rejected, denoted by "N".

The loan status is the responding variable of this analysis and therefore the unbalanced sample size from both "Y" and "N" may badly affect the predictive model (sensitivity and specificity) built in the later machine learning section. It is a good note here and will be considered during models building and evaluation.

```{r, message=FALSE, warning=FALSE}

# set up dataframe

df6.1.1 <- train.data %>% 
  select(Loan_Status) %>% 
  group_by(Loan_Status) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  mutate(total = sum(count),
         per = round(count/total, 1))

# plot

ggplot(df6.1.1, aes(x = "", y = count, fill = Loan_Status)) +
  geom_bar(stat = 'identity') +
  coord_polar(theta = "y", start = 0) +
  theme_minimal() +
  theme(axis.title = element_blank(),
        legend.position = "none",
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_label(aes(label = paste0(Loan_Status, "\n", count, " (", per*100, " %)")),
             position = position_stack(vjust = 0.5),
             size = 4) +
  labs(title = "70% Of Applications have been Approved",
       subtitle = "(Train data)")

```

### 6.2 Gender vs Approval Rate 

It will be interesting to see the number of female and male applicants and would gender affect loan approval. Data shows that:

* There were lesser female applicants (109) than male applicants (483).

* However, the loan success rate of both gender are the same, both arrive at 70%. 

```{r, fig.width = 8, message=FALSE}

# set up dataframe

df6.1.2 <- train.data %>% 
  select(Loan_Status, Gender) %>% 
  group_by(Loan_Status, Gender) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  group_by(Gender) %>% 
  mutate(total = sum(count),
         per = round(count/total, 1))

# plot

ggplot(df6.1.2, aes(x = "", y = count, fill = Loan_Status)) +
  geom_bar(stat = 'identity') +
  coord_polar(theta = "y", start = 0) +
  theme_minimal() +
  theme(axis.title = element_blank(),
        legend.position = "none",
        plot.title = element_text(hjust = 0.5,
                                  face = "bold"),
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_label(aes(label = paste0(Loan_Status, "\n", count, " (", per*100, " %)")),
             position = position_stack(vjust = 0.5),
             size = 4) +
  labs(title = "Both Gender have similar proportion",
       subtitle = "(Train data)") +
  facet_wrap(~ Gender)


```
Female Applicants:

```{r}
73+36
```
Male Applicants:

```{r}
145+338
```



### 6.2 Gender, Applicant Income, and Loan_Status

*Insights*

* For Female applicants, both approved and rejected applicants have similar primary applicant incomes.
* For Male applicants, both approved and rejected applicants have similar primary applicant incomes.
* There are more male applicants than female.
* As indicated by overlapping of all 4 boxplots and the medians, there is no obvious income different between both genders. 

The approval of loan seems do not affected obviously by applicant income. The income of co-applicant or the combination my have an effect. 

```{r}

ggplot(train.data, aes(x = Loan_Status, y = log(ApplicantIncome), colour = Loan_Status)) +
  geom_jitter(size = 2, alpha = 0.5, alpha = 0.8) + 
  geom_boxplot(outlier.shape = NA, colour = "black", alpha = 0) +
  facet_wrap(~Gender) +
  theme_bw() +
  theme(strip.text = element_text(size = 15, colour = "white"),
        strip.background = element_rect(fill = "grey20"),
        plot.title = element_text(size = 15, face = 'bold'),
        legend.position = "NA") +
  labs(x = "Loan Status", 
       y = "Applicant Income (log10)",
       title = "Gender and Applicant Income on Loan Approval") 


```


```{r}
(21+9)/155

```






## Machine Learning

### Oversampling  


```{r}
library(rose)

```



##  REFERENCE


https://www.kaggle.com/altruistdelhite04/loan-prediction-problem-dataset
